{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c327d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600, 16)\n",
      "           state   district      N     P      K    pH  organic_carbon  \\\n",
      "0  Uttar Pradesh  Chandauli  213.9   3.3  114.2  6.38            0.96   \n",
      "1    Maharashtra       Beed  165.0  26.1  165.4  5.08            0.93   \n",
      "2          Bihar    Bhojpur  191.1  28.2   46.4  5.24            1.09   \n",
      "3      Rajasthan  Rajsamand  186.4  17.5   55.9  6.04            0.55   \n",
      "4      Rajasthan      Churu  203.7  15.5  194.4  5.87            1.03   \n",
      "\n",
      "   soil_moisture     soil_type  temperature_c  humidity_pct  rainfall_mm  \\\n",
      "0           30.1        Clayey           24.0            46        217.6   \n",
      "1           16.4  Black Cotton           27.5            49         37.7   \n",
      "2           16.6      Laterite           30.5            61          0.0   \n",
      "3           17.3         Sandy           26.9            64        239.5   \n",
      "4           12.0         Sandy           29.6            48        142.9   \n",
      "\n",
      "   wind_speed_ms  solar_radiation_wm2  evapotranspiration_mm         crop  \n",
      "0           0.99                463.7                   3.94        Onion  \n",
      "1           0.10                406.9                   4.48      Tobacco  \n",
      "2           1.63                400.8                   1.71      Soybean  \n",
      "3           0.50                568.1                   2.74         Rice  \n",
      "4           1.84                468.4                   1.56  Bengal Gram  \n"
     ]
    }
   ],
   "source": [
    "#step-1 : Loading the Dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"final_balanced_crop_dataset_4600_all_districts.csv\")\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56e2b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   state                  4600 non-null   object \n",
      " 1   district               4600 non-null   object \n",
      " 2   N                      4600 non-null   float64\n",
      " 3   P                      4600 non-null   float64\n",
      " 4   K                      4600 non-null   float64\n",
      " 5   pH                     4600 non-null   float64\n",
      " 6   organic_carbon         4600 non-null   float64\n",
      " 7   soil_moisture          4600 non-null   float64\n",
      " 8   soil_type              4600 non-null   object \n",
      " 9   temperature_c          4600 non-null   float64\n",
      " 10  humidity_pct           4600 non-null   int64  \n",
      " 11  rainfall_mm            4600 non-null   float64\n",
      " 12  wind_speed_ms          4600 non-null   float64\n",
      " 13  solar_radiation_wm2    4600 non-null   float64\n",
      " 14  evapotranspiration_mm  4600 non-null   float64\n",
      " 15  crop                   4600 non-null   object \n",
      "dtypes: float64(11), int64(1), object(4)\n",
      "memory usage: 575.1+ KB\n",
      "None\n",
      "state                    0\n",
      "district                 0\n",
      "N                        0\n",
      "P                        0\n",
      "K                        0\n",
      "pH                       0\n",
      "organic_carbon           0\n",
      "soil_moisture            0\n",
      "soil_type                0\n",
      "temperature_c            0\n",
      "humidity_pct             0\n",
      "rainfall_mm              0\n",
      "wind_speed_ms            0\n",
      "solar_radiation_wm2      0\n",
      "evapotranspiration_mm    0\n",
      "crop                     0\n",
      "dtype: int64\n",
      "crop\n",
      "Onion          200\n",
      "Tobacco        200\n",
      "Soybean        200\n",
      "Rice           200\n",
      "Bengal Gram    200\n",
      "Sugarcane      200\n",
      "Banana         200\n",
      "Tomato         200\n",
      "Toor           200\n",
      "Moong          200\n",
      "Sunflower      200\n",
      "Bajra          200\n",
      "Wheat          200\n",
      "Ragi           200\n",
      "Maize          200\n",
      "Urad           200\n",
      "Groundnut      200\n",
      "Coconut        200\n",
      "Cotton         200\n",
      "Mirchi         200\n",
      "Mustard        200\n",
      "Sorghum        200\n",
      "Potato         200\n",
      "Name: count, dtype: int64\n",
      "                 N            P            K           pH  organic_carbon  \\\n",
      "count  4600.000000  4600.000000  4600.000000  4600.000000     4600.000000   \n",
      "mean    220.686674    19.981065   151.432370     6.498857        0.802952   \n",
      "std      80.528133     8.759452    69.717358     0.503491        0.249780   \n",
      "min       5.000000     1.000000     5.000000     4.660000        0.100000   \n",
      "25%     166.700000    13.900000   103.275000     6.160000        0.630000   \n",
      "50%     220.550000    19.800000   150.250000     6.500000        0.810000   \n",
      "75%     275.825000    25.900000   198.600000     6.840000        0.970000   \n",
      "max     508.200000    53.700000   402.200000     8.740000        1.720000   \n",
      "\n",
      "       soil_moisture  temperature_c  humidity_pct  rainfall_mm  wind_speed_ms  \\\n",
      "count    4600.000000    4600.000000   4600.000000  4600.000000    4600.000000   \n",
      "mean       25.134391      26.950196     60.227826   106.319652       1.204676   \n",
      "std         9.901161       4.034437     17.753986    78.556223       0.651958   \n",
      "min         1.000000       9.800000      5.000000     0.000000       0.100000   \n",
      "25%        18.400000      24.200000     48.000000    41.575000       0.707500   \n",
      "50%        25.300000      26.950000     61.000000   102.450000       1.180000   \n",
      "75%        31.900000      29.700000     73.000000   160.200000       1.660000   \n",
      "max        63.500000      41.100000    100.000000   435.500000       3.530000   \n",
      "\n",
      "       solar_radiation_wm2  evapotranspiration_mm  \n",
      "count          4600.000000            4600.000000  \n",
      "mean            450.317957               2.992183  \n",
      "std             120.360029               1.186501  \n",
      "min              50.000000               0.100000  \n",
      "25%             368.675000               2.190000  \n",
      "50%             448.550000               2.990000  \n",
      "75%             532.525000               3.780000  \n",
      "max             855.300000               7.730000  \n"
     ]
    }
   ],
   "source": [
    "#step-2 : showing info and quick stats\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "print(df['crop'].value_counts())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47e120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['state', 'N', 'P', 'K', 'pH', 'organic_carbon', 'soil_moisture',\n",
      "       'soil_type', 'temperature_c', 'humidity_pct', 'rainfall_mm',\n",
      "       'wind_speed_ms', 'solar_radiation_wm2', 'evapotranspiration_mm',\n",
      "       'crop'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#step-3: Drop obvious identifiers\n",
    "if 'district' in df.columns and df['district'].nunique() > 50:\n",
    "    df = df.drop(columns=['district'])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe857a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bajra': np.int64(0), 'Banana': np.int64(1), 'Bengal Gram': np.int64(2), 'Coconut': np.int64(3), 'Cotton': np.int64(4), 'Groundnut': np.int64(5), 'Maize': np.int64(6), 'Mirchi': np.int64(7), 'Moong': np.int64(8), 'Mustard': np.int64(9), 'Onion': np.int64(10), 'Potato': np.int64(11), 'Ragi': np.int64(12), 'Rice': np.int64(13), 'Sorghum': np.int64(14), 'Soybean': np.int64(15), 'Sugarcane': np.int64(16), 'Sunflower': np.int64(17), 'Tobacco': np.int64(18), 'Tomato': np.int64(19), 'Toor': np.int64(20), 'Urad': np.int64(21), 'Wheat': np.int64(22)}\n"
     ]
    }
   ],
   "source": [
    "#Step 4 — Prepare X and y, show label mapping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df.drop(columns=['crop'])\n",
    "y = df['crop'].astype(str)\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "print(dict(zip(le.classes_, le.transform(le.classes_))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09c937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric: ['N', 'P', 'K', 'pH', 'organic_carbon', 'soil_moisture', 'temperature_c', 'humidity_pct', 'rainfall_mm', 'wind_speed_ms', 'solar_radiation_wm2', 'evapotranspiration_mm']\n",
      "Categorical: ['state', 'soil_type']\n"
     ]
    }
   ],
   "source": [
    "#Step 5 — Identify numeric & categorical columns\n",
    "num_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "print(\"Numeric:\", num_cols)\n",
    "print(\"Categorical:\", cat_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46226e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19893147 -1.59278251  0.02423594 -1.39499377  0.46281453 -0.94179839\n",
      "  -0.42245864  0.2532529  -0.95653505 -0.06845166 -1.50092018  0.65263974\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          1.          1.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.73748152 -0.0393822   1.74440944  0.9701105  -0.80677731 -2.3025157\n",
      "   0.12415643  1.38291433  0.61966241  1.69580719 -0.59768735 -0.11308822\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.          0.          0.\n",
      "   0.          0.          0.          1.          0.        ]\n",
      " [-0.20124114 -0.13143555  1.41737478 -1.76946862  0.42313978  1.09927758\n",
      "  -1.81384246 -0.08564553  1.04251377 -0.82677345  0.25705527 -0.94688088\n",
      "   0.          0.          1.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.          0.        ]\n",
      " [ 1.91431312  0.04116448 -1.59076782 -0.27156924  0.06606708  0.44938274\n",
      "  -0.22368953 -1.04585774 -1.32368144 -0.71844177 -0.55741583 -1.151075\n",
      "   0.          1.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          1.          0.        ]\n",
      " [-0.29598606 -0.67224899  0.21872792  0.00435959  0.97858621 -2.4446802\n",
      "  -0.8945353   0.53566826 -0.01967873  0.81367776  0.25048032 -0.13010439\n",
      "   0.          0.          1.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.          0.        ]]\n",
      "(5, 29)\n"
     ]
    }
   ],
   "source": [
    "#Step 6 — Build preprocessing (impute, encode, scale) — do NOT fit it yet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                     ('scaler', StandardScaler())])\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer([('num', num_pipe, num_cols),\n",
    "                                  ('cat', cat_pipe, cat_cols)],\n",
    "                                 remainder='drop', sparse_threshold=0)\n",
    "\n",
    "#Step 7 — Stratified split (hold-out test set)\n",
    "X = df.drop(columns=['crop'])\n",
    "y = df['crop'].astype(str)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.20, random_state=42, stratify=y_enc\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor.fit(X_train)\n",
    "sample = preprocessor.transform(X_train.head(5))\n",
    "print(sample)\n",
    "print(sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23a6d218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV acc mean/std: 0.0470108695652174 0.006291215708038164\n",
      "CV f1_macro mean: 0.045877421239571656\n",
      "Test accuracy: 0.05\n",
      "Test f1_macro: 0.046329229069181514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        40\n",
      "           1     0.0000    0.0000    0.0000        40\n",
      "           2     0.0556    0.0500    0.0526        40\n",
      "           3     0.0513    0.0500    0.0506        40\n",
      "           4     0.0417    0.0250    0.0312        40\n",
      "           5     0.0484    0.0750    0.0588        40\n",
      "           6     0.1111    0.1250    0.1176        40\n",
      "           7     0.0556    0.1000    0.0714        40\n",
      "           8     0.0698    0.0750    0.0723        40\n",
      "           9     0.0000    0.0000    0.0000        40\n",
      "          10     0.0667    0.0750    0.0706        40\n",
      "          11     0.0000    0.0000    0.0000        40\n",
      "          12     0.0492    0.0750    0.0594        40\n",
      "          13     0.0741    0.1000    0.0851        40\n",
      "          14     0.0690    0.0500    0.0580        40\n",
      "          15     0.0182    0.0250    0.0211        40\n",
      "          16     0.0227    0.0250    0.0238        40\n",
      "          17     0.0769    0.0750    0.0759        40\n",
      "          18     0.0556    0.0250    0.0345        40\n",
      "          19     0.0357    0.0500    0.0417        40\n",
      "          20     0.0000    0.0000    0.0000        40\n",
      "          21     0.0541    0.0500    0.0519        40\n",
      "          22     0.0800    0.1000    0.0889        40\n",
      "\n",
      "    accuracy                         0.0500       920\n",
      "   macro avg     0.0450    0.0500    0.0463       920\n",
      "weighted avg     0.0450    0.0500    0.0463       920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Step 8 — Train models + evaluate (example: one model), then loop 9 models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "pipe = Pipeline([('pre', preprocessor), ('clf', LogisticRegression(max_iter=1000, multi_class='multinomial'))])\n",
    "\n",
    "# Cross-validate on TRAIN only\n",
    "scores_acc = cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy', n_jobs=1)\n",
    "scores_f1  = cross_val_score(pipe, X_train, y_train, cv=5, scoring='f1_macro', n_jobs=1)\n",
    "print(\"CV acc mean/std:\", scores_acc.mean(), scores_acc.std())\n",
    "print(\"CV f1_macro mean:\", scores_f1.mean())\n",
    "\n",
    "# Fit on full train and evaluate on held-out TEST\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Test f1_macro:\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(classification_report(y_test, y_pred, zero_division=0, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "056110e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree CV Accuracy: 0.04891304347826087\n",
      "Decision Tree CV F1: 0.048895988969093106\n",
      "Decision Tree Test Accuracy: 0.04673913043478261\n",
      "Decision Tree Test F1: 0.04747818267862513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.02      0.03      0.02        40\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.00      0.00      0.00        40\n",
      "           4       0.04      0.03      0.03        40\n",
      "           5       0.05      0.05      0.05        40\n",
      "           6       0.00      0.00      0.00        40\n",
      "           7       0.16      0.12      0.14        40\n",
      "           8       0.02      0.03      0.02        40\n",
      "           9       0.04      0.05      0.05        40\n",
      "          10       0.06      0.05      0.05        40\n",
      "          11       0.02      0.03      0.02        40\n",
      "          12       0.06      0.07      0.07        40\n",
      "          13       0.05      0.05      0.05        40\n",
      "          14       0.05      0.05      0.05        40\n",
      "          15       0.06      0.05      0.05        40\n",
      "          16       0.08      0.07      0.08        40\n",
      "          17       0.05      0.05      0.05        40\n",
      "          18       0.11      0.10      0.10        40\n",
      "          19       0.05      0.05      0.05        40\n",
      "          20       0.05      0.05      0.05        40\n",
      "          21       0.07      0.07      0.07        40\n",
      "          22       0.08      0.07      0.08        40\n",
      "\n",
      "    accuracy                           0.05       920\n",
      "   macro avg       0.05      0.05      0.05       920\n",
      "weighted avg       0.05      0.05      0.05       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Build pipeline\n",
    "dt_pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),   # use same preprocessor\n",
    "    ('model', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Cross-validation accuracy (train set)\n",
    "dt_cv_acc = cross_val_score(dt_pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "dt_cv_f1  = cross_val_score(dt_pipe, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "print(\"Decision Tree CV Accuracy:\", dt_cv_acc.mean())\n",
    "print(\"Decision Tree CV F1:\", dt_cv_f1.mean())\n",
    "\n",
    "# Fit and test on test set\n",
    "dt_pipe.fit(X_train, y_train)\n",
    "y_pred_dt = dt_pipe.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Test Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Decision Tree Test F1:\", f1_score(y_test, y_pred_dt, average='macro'))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efdc2c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CV Accuracy: 0.04646739130434782\n",
      "Random Forest CV F1: 0.04599726163331714\n",
      "Random Forest Test Accuracy: 0.04782608695652174\n",
      "Random Forest Test F1: 0.04758085321375871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.05      0.05        40\n",
      "           1       0.02      0.03      0.02        40\n",
      "           2       0.11      0.10      0.11        40\n",
      "           3       0.04      0.05      0.04        40\n",
      "           4       0.00      0.00      0.00        40\n",
      "           5       0.02      0.03      0.02        40\n",
      "           6       0.03      0.03      0.03        40\n",
      "           7       0.06      0.07      0.07        40\n",
      "           8       0.02      0.03      0.02        40\n",
      "           9       0.06      0.05      0.05        40\n",
      "          10       0.07      0.10      0.08        40\n",
      "          11       0.09      0.07      0.08        40\n",
      "          12       0.02      0.03      0.02        40\n",
      "          13       0.00      0.00      0.00        40\n",
      "          14       0.07      0.07      0.07        40\n",
      "          15       0.05      0.05      0.05        40\n",
      "          16       0.04      0.03      0.03        40\n",
      "          17       0.09      0.07      0.08        40\n",
      "          18       0.04      0.03      0.03        40\n",
      "          19       0.09      0.10      0.10        40\n",
      "          20       0.03      0.03      0.03        40\n",
      "          21       0.03      0.03      0.03        40\n",
      "          22       0.08      0.07      0.08        40\n",
      "\n",
      "    accuracy                           0.05       920\n",
      "   macro avg       0.05      0.05      0.05       920\n",
      "weighted avg       0.05      0.05      0.05       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "rf_cv_acc = cross_val_score(rf_pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "rf_cv_f1  = cross_val_score(rf_pipe, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "print(\"Random Forest CV Accuracy:\", rf_cv_acc.mean())\n",
    "print(\"Random Forest CV F1:\", rf_cv_f1.mean())\n",
    "\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipe.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest Test F1:\", f1_score(y_test, y_pred_rf, average='macro'))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb434d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting CV Accuracy: 0.04076086956521739\n",
      "Gradient Boosting CV F1: 0.04009842120531465\n",
      "Gradient Boosting Test Accuracy: 0.03152173913043478\n",
      "Gradient Boosting Test F1: 0.031924179313963914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.10      0.11        40\n",
      "           1       0.06      0.05      0.05        40\n",
      "           2       0.05      0.05      0.05        40\n",
      "           3       0.07      0.07      0.07        40\n",
      "           4       0.03      0.03      0.03        40\n",
      "           5       0.00      0.00      0.00        40\n",
      "           6       0.00      0.00      0.00        40\n",
      "           7       0.02      0.03      0.02        40\n",
      "           8       0.04      0.05      0.05        40\n",
      "           9       0.03      0.03      0.03        40\n",
      "          10       0.00      0.00      0.00        40\n",
      "          11       0.00      0.00      0.00        40\n",
      "          12       0.04      0.05      0.05        40\n",
      "          13       0.03      0.03      0.03        40\n",
      "          14       0.08      0.05      0.06        40\n",
      "          15       0.03      0.03      0.03        40\n",
      "          16       0.00      0.00      0.00        40\n",
      "          17       0.00      0.00      0.00        40\n",
      "          18       0.03      0.03      0.03        40\n",
      "          19       0.06      0.07      0.07        40\n",
      "          20       0.02      0.03      0.02        40\n",
      "          21       0.00      0.00      0.00        40\n",
      "          22       0.05      0.05      0.05        40\n",
      "\n",
      "    accuracy                           0.03       920\n",
      "   macro avg       0.03      0.03      0.03       920\n",
      "weighted avg       0.03      0.03      0.03       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "gb_cv_acc = cross_val_score(gb_pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "gb_cv_f1  = cross_val_score(gb_pipe, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "print(\"Gradient Boosting CV Accuracy:\", gb_cv_acc.mean())\n",
    "print(\"Gradient Boosting CV F1:\", gb_cv_f1.mean())\n",
    "\n",
    "gb_pipe.fit(X_train, y_train)\n",
    "y_pred_gb = gb_pipe.predict(X_test)\n",
    "\n",
    "print(\"Gradient Boosting Test Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"Gradient Boosting Test F1:\", f1_score(y_test, y_pred_gb, average='macro'))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3842b272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees CV Accuracy: 0.04755434782608696\n",
      "Extra Trees CV F1: 0.046874636193819416\n",
      "Extra Trees Test Accuracy: 0.04891304347826087\n",
      "Extra Trees Test F1: 0.04959036650845489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.03      0.02        40\n",
      "           1       0.04      0.05      0.04        40\n",
      "           2       0.07      0.07      0.07        40\n",
      "           3       0.02      0.03      0.02        40\n",
      "           4       0.07      0.05      0.06        40\n",
      "           5       0.04      0.05      0.04        40\n",
      "           6       0.11      0.07      0.09        40\n",
      "           7       0.00      0.00      0.00        40\n",
      "           8       0.03      0.03      0.03        40\n",
      "           9       0.03      0.03      0.03        40\n",
      "          10       0.09      0.10      0.10        40\n",
      "          11       0.07      0.05      0.06        40\n",
      "          12       0.07      0.07      0.07        40\n",
      "          13       0.05      0.05      0.05        40\n",
      "          14       0.05      0.05      0.05        40\n",
      "          15       0.04      0.05      0.05        40\n",
      "          16       0.00      0.00      0.00        40\n",
      "          17       0.05      0.05      0.05        40\n",
      "          18       0.06      0.05      0.05        40\n",
      "          19       0.08      0.07      0.08        40\n",
      "          20       0.06      0.05      0.05        40\n",
      "          21       0.03      0.03      0.03        40\n",
      "          22       0.10      0.10      0.10        40\n",
      "\n",
      "    accuracy                           0.05       920\n",
      "   macro avg       0.05      0.05      0.05       920\n",
      "weighted avg       0.05      0.05      0.05       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et_pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', ExtraTreesClassifier(n_estimators=300, random_state=42))\n",
    "])\n",
    "\n",
    "et_cv_acc = cross_val_score(et_pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "et_cv_f1  = cross_val_score(et_pipe, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "print(\"Extra Trees CV Accuracy:\", et_cv_acc.mean())\n",
    "print(\"Extra Trees CV F1:\", et_cv_f1.mean())\n",
    "\n",
    "et_pipe.fit(X_train, y_train)\n",
    "y_pred_et = et_pipe.predict(X_test)\n",
    "\n",
    "print(\"Extra Trees Test Accuracy:\", accuracy_score(y_test, y_pred_et))\n",
    "print(\"Extra Trees Test F1:\", f1_score(y_test, y_pred_et, average='macro'))\n",
    "print(classification_report(y_test, y_pred_et))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ae9f002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CV Accuracy: 0.037228260869565225\n",
      "KNN CV F1: 0.02946739870349337\n",
      "KNN Test Accuracy: 0.042391304347826085\n",
      "KNN Test F1: 0.037067906658821856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.07      0.03        40\n",
      "           1       0.05      0.15      0.08        40\n",
      "           2       0.03      0.07      0.04        40\n",
      "           3       0.06      0.15      0.09        40\n",
      "           4       0.03      0.05      0.04        40\n",
      "           5       0.04      0.07      0.05        40\n",
      "           6       0.03      0.03      0.03        40\n",
      "           7       0.04      0.05      0.05        40\n",
      "           8       0.12      0.07      0.09        40\n",
      "           9       0.04      0.03      0.03        40\n",
      "          10       0.00      0.00      0.00        40\n",
      "          11       0.18      0.07      0.11        40\n",
      "          12       0.00      0.00      0.00        40\n",
      "          13       0.07      0.03      0.04        40\n",
      "          14       0.00      0.00      0.00        40\n",
      "          15       0.05      0.03      0.03        40\n",
      "          16       0.06      0.03      0.03        40\n",
      "          17       0.00      0.00      0.00        40\n",
      "          18       0.00      0.00      0.00        40\n",
      "          19       0.00      0.00      0.00        40\n",
      "          20       0.00      0.00      0.00        40\n",
      "          21       0.14      0.05      0.07        40\n",
      "          22       0.08      0.03      0.04        40\n",
      "\n",
      "    accuracy                           0.04       920\n",
      "   macro avg       0.05      0.04      0.04       920\n",
      "weighted avg       0.05      0.04      0.04       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn_cv_acc = cross_val_score(knn_pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "knn_cv_f1  = cross_val_score(knn_pipe, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "print(\"KNN CV Accuracy:\", knn_cv_acc.mean())\n",
    "print(\"KNN CV F1:\", knn_cv_f1.mean())\n",
    "\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "y_pred_knn = knn_pipe.predict(X_test)\n",
    "\n",
    "print(\"KNN Test Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"KNN Test F1:\", f1_score(y_test, y_pred_knn, average='macro'))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f4d1f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes CV Accuracy: 0.050815217391304346\n",
      "Naive Bayes CV F1: 0.048038095437600535\n",
      "Naive Bayes Test Accuracy: 0.043478260869565216\n",
      "Naive Bayes Test F1: 0.03957860105003538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.02      0.03      0.02        40\n",
      "           2       0.05      0.05      0.05        40\n",
      "           3       0.03      0.03      0.03        40\n",
      "           4       0.00      0.00      0.00        40\n",
      "           5       0.02      0.03      0.02        40\n",
      "           6       0.08      0.10      0.09        40\n",
      "           7       0.04      0.05      0.04        40\n",
      "           8       0.00      0.00      0.00        40\n",
      "           9       0.00      0.00      0.00        40\n",
      "          10       0.06      0.12      0.08        40\n",
      "          11       0.00      0.00      0.00        40\n",
      "          12       0.05      0.10      0.07        40\n",
      "          13       0.05      0.07      0.06        40\n",
      "          14       0.21      0.07      0.11        40\n",
      "          15       0.03      0.07      0.04        40\n",
      "          16       0.06      0.05      0.05        40\n",
      "          17       0.11      0.10      0.10        40\n",
      "          18       0.17      0.03      0.04        40\n",
      "          19       0.03      0.03      0.03        40\n",
      "          20       0.03      0.03      0.03        40\n",
      "          21       0.00      0.00      0.00        40\n",
      "          22       0.04      0.05      0.04        40\n",
      "\n",
      "    accuracy                           0.04       920\n",
      "   macro avg       0.05      0.04      0.04       920\n",
      "weighted avg       0.05      0.04      0.04       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', GaussianNB())\n",
    "])\n",
    "\n",
    "nb_cv_acc = cross_val_score(nb_pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "nb_cv_f1  = cross_val_score(nb_pipe, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "print(\"Naive Bayes CV Accuracy:\", nb_cv_acc.mean())\n",
    "print(\"Naive Bayes CV F1:\", nb_cv_f1.mean())\n",
    "\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "y_pred_nb = nb_pipe.predict(X_test)\n",
    "\n",
    "print(\"Naive Bayes Test Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Naive Bayes Test F1:\", f1_score(y_test, y_pred_nb, average='macro'))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01ae0ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CV Accuracy: 0.04592391304347826\n",
      "SVM CV F1: 0.044547801797251055\n",
      "SVM Test Accuracy: 0.041304347826086954\n",
      "SVM Test F1: 0.03967665883411355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.00      0.00      0.00        40\n",
      "           2       0.09      0.10      0.09        40\n",
      "           3       0.04      0.05      0.05        40\n",
      "           4       0.06      0.07      0.07        40\n",
      "           5       0.02      0.03      0.02        40\n",
      "           6       0.00      0.00      0.00        40\n",
      "           7       0.05      0.07      0.06        40\n",
      "           8       0.06      0.07      0.06        40\n",
      "           9       0.03      0.03      0.03        40\n",
      "          10       0.04      0.05      0.04        40\n",
      "          11       0.05      0.05      0.05        40\n",
      "          12       0.07      0.07      0.07        40\n",
      "          13       0.03      0.03      0.03        40\n",
      "          14       0.04      0.03      0.03        40\n",
      "          15       0.00      0.00      0.00        40\n",
      "          16       0.02      0.03      0.02        40\n",
      "          17       0.04      0.05      0.05        40\n",
      "          18       0.04      0.03      0.03        40\n",
      "          19       0.06      0.07      0.07        40\n",
      "          20       0.00      0.00      0.00        40\n",
      "          21       0.06      0.05      0.05        40\n",
      "          22       0.11      0.07      0.09        40\n",
      "\n",
      "    accuracy                           0.04       920\n",
      "   macro avg       0.04      0.04      0.04       920\n",
      "weighted avg       0.04      0.04      0.04       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', SVC(kernel='rbf'))\n",
    "])\n",
    "\n",
    "svm_cv_acc = cross_val_score(svm_pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "svm_cv_f1  = cross_val_score(svm_pipe, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "print(\"SVM CV Accuracy:\", svm_cv_acc.mean())\n",
    "print(\"SVM CV F1:\", svm_cv_f1.mean())\n",
    "\n",
    "svm_pipe.fit(X_train, y_train)\n",
    "y_pred_svm = svm_pipe.predict(X_test)\n",
    "\n",
    "print(\"SVM Test Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"SVM Test F1:\", f1_score(y_test, y_pred_svm, average='macro'))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83e3b7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP NN CV Accuracy: 0.049184782608695646\n",
      "MLP NN CV F1: 0.04872765873455245\n",
      "MLP Test Accuracy: 0.03695652173913044\n",
      "MLP Test F1: 0.036223998890237065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.05      0.05        40\n",
      "           1       0.07      0.07      0.07        40\n",
      "           2       0.02      0.03      0.02        40\n",
      "           3       0.00      0.00      0.00        40\n",
      "           4       0.03      0.03      0.03        40\n",
      "           5       0.03      0.03      0.03        40\n",
      "           6       0.06      0.07      0.07        40\n",
      "           7       0.05      0.05      0.05        40\n",
      "           8       0.03      0.03      0.03        40\n",
      "           9       0.02      0.03      0.02        40\n",
      "          10       0.02      0.03      0.02        40\n",
      "          11       0.02      0.03      0.02        40\n",
      "          12       0.03      0.03      0.03        40\n",
      "          13       0.00      0.00      0.00        40\n",
      "          14       0.12      0.15      0.13        40\n",
      "          15       0.03      0.03      0.03        40\n",
      "          16       0.02      0.03      0.02        40\n",
      "          17       0.05      0.05      0.05        40\n",
      "          18       0.10      0.07      0.09        40\n",
      "          19       0.00      0.00      0.00        40\n",
      "          20       0.00      0.00      0.00        40\n",
      "          21       0.02      0.03      0.02        40\n",
      "          22       0.05      0.05      0.05        40\n",
      "\n",
      "    accuracy                           0.04       920\n",
      "   macro avg       0.04      0.04      0.04       920\n",
      "weighted avg       0.04      0.04      0.04       920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', MLPClassifier(hidden_layer_sizes=(128,64), max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "mlp_cv_acc = cross_val_score(mlp_pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "mlp_cv_f1  = cross_val_score(mlp_pipe, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "print(\"MLP NN CV Accuracy:\", mlp_cv_acc.mean())\n",
    "print(\"MLP NN CV F1:\", mlp_cv_f1.mean())\n",
    "\n",
    "mlp_pipe.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_pipe.predict(X_test)\n",
    "\n",
    "print(\"MLP Test Accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
    "print(\"MLP Test F1:\", f1_score(y_test, y_pred_mlp, average='macro'))\n",
    "print(classification_report(y_test, y_pred_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916e368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
